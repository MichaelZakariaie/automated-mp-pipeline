{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a0d1d13",
   "metadata": {},
   "source": [
    "PTSD modeling & exploration (`yochlol` env)\n",
    "\n",
    "[Jump to SKIP & LOAD](#skip-&-load) if you want to skip Athena queries, loading, & cleaning and just start modeling off of 262 sessions (as of 2025-06-23)\n",
    "\n",
    "* vary target (PTSD, Trauma, PTSD threshold, PCL regression, other questionnaires...)\n",
    "* 1 task, different tasks\n",
    "* make reasonable baselines\n",
    "* simple features, complex features, leave 1 feature out/feature importance with sklearn/SHAP, lofo-importance lib\n",
    "* compare simple faster high bias models with powerful more complex data-hungry models\n",
    "* catch22 or other ts feats/tsfresh, tsflex, tsfel\n",
    "* time-series-autoencoder (JulesBelveze), SimTSC (daochenzha)\n",
    "* mvts transformer\n",
    "* other deep learning approaches\n",
    "* etc. billion other things here and elsewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e697b2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import fireducks.pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mplcyberpunk\n",
    "plt.style.use('cyberpunk')\n",
    "from tqdm import tqdm\n",
    "import awswrangler as wr\n",
    "#from flaml import AutoML\n",
    "\n",
    "# import dask.array as da\n",
    "# import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81475a1",
   "metadata": {},
   "source": [
    "## ingest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bfd0cc0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 108\u001b[39m\n\u001b[32m    106\u001b[39m df = wr.athena.read_sql_query(QUERY, database=DATABASE, ctas_approach=\u001b[38;5;28;01mTrue\u001b[39;00m, chunksize=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    107\u001b[39m \u001b[38;5;66;03m# concat the generator of dataframes returned by chunksize=True\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m dfcve = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m dfcve[\u001b[33m'\u001b[39m\u001b[33munique_id\u001b[39m\u001b[33m'\u001b[39m] = dfcve[\u001b[33m'\u001b[39m\u001b[33msession_id\u001b[39m\u001b[33m'\u001b[39m].apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x.split(\u001b[33m'\u001b[39m\u001b[33m_\u001b[39m\u001b[33m'\u001b[39m)[\u001b[32m0\u001b[39m])\n\u001b[32m    112\u001b[39m \u001b[38;5;66;03m# Quality stuff\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/yochlol/lib/python3.11/site-packages/pandas/core/reshape/concat.py:382\u001b[39m, in \u001b[36mconcat\u001b[39m\u001b[34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[39m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[32m    380\u001b[39m     copy = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m382\u001b[39m op = \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m op.get_result()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/yochlol/lib/python3.11/site-packages/pandas/core/reshape/concat.py:445\u001b[39m, in \u001b[36m_Concatenator.__init__\u001b[39m\u001b[34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[39m\n\u001b[32m    442\u001b[39m \u001b[38;5;28mself\u001b[39m.verify_integrity = verify_integrity\n\u001b[32m    443\u001b[39m \u001b[38;5;28mself\u001b[39m.copy = copy\n\u001b[32m--> \u001b[39m\u001b[32m445\u001b[39m objs, keys = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    447\u001b[39m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[32m    448\u001b[39m ndims = \u001b[38;5;28mself\u001b[39m._get_ndims(objs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/yochlol/lib/python3.11/site-packages/pandas/core/reshape/concat.py:504\u001b[39m, in \u001b[36m_Concatenator._clean_keys_and_objs\u001b[39m\u001b[34m(self, objs, keys)\u001b[39m\n\u001b[32m    502\u001b[39m     objs_list = [objs[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m keys]\n\u001b[32m    503\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m504\u001b[39m     objs_list = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) == \u001b[32m0\u001b[39m:\n\u001b[32m    507\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo objects to concatenate\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/yochlol/lib/python3.11/site-packages/awswrangler/athena/_read.py:77\u001b[39m, in \u001b[36m_add_query_metadata_generator\u001b[39m\u001b[34m(dfs, query_metadata)\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_add_query_metadata_generator\u001b[39m(\n\u001b[32m     74\u001b[39m     dfs: Iterator[pd.DataFrame], query_metadata: _QueryMetadata\n\u001b[32m     75\u001b[39m ) -> Iterator[pd.DataFrame]:\n\u001b[32m     76\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Add Query Execution metadata to every DF in iterator.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdfs\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m_apply_query_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_metadata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# noqa: PLW2901\u001b[39;49;00m\n\u001b[32m     79\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/yochlol/lib/python3.11/site-packages/awswrangler/s3/_read_parquet.py:258\u001b[39m, in \u001b[36m_read_parquet_chunked\u001b[39m\u001b[34m(s3_client, paths, path_root, columns, coerce_int96_timestamp_unit, chunked, use_threads, s3_additional_kwargs, arrow_kwargs, version_ids, decryption_properties)\u001b[39m\n\u001b[32m    256\u001b[39m table_kwargs = {\u001b[33m\"\u001b[39m\u001b[33mpath\u001b[39m\u001b[33m\"\u001b[39m: path, \u001b[33m\"\u001b[39m\u001b[33mpath_root\u001b[39m\u001b[33m\"\u001b[39m: path_root}\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m metadata.num_rows > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpq_file\u001b[49m\u001b[43m.\u001b[49m\u001b[43miter_batches\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_threads\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_threads_flag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_pandas_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m    260\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m_add_table_partitions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpa\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTable\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_batches\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtable_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m_table_to_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43marrow_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/yochlol/lib/python3.11/site-packages/pyarrow/_parquet.pyx:1626\u001b[39m, in \u001b[36miter_batches\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/yochlol/lib/python3.11/site-packages/pyarrow/error.pxi:89\u001b[39m, in \u001b[36mpyarrow.lib.check_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/yochlol/lib/python3.11/site-packages/awswrangler/s3/_fs.py:521\u001b[39m, in \u001b[36m_S3ObjectBase.read\u001b[39m\u001b[34m(self, length)\u001b[39m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m length < \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._loc + length > \u001b[38;5;28mself\u001b[39m._size:\n\u001b[32m    519\u001b[39m     length = \u001b[38;5;28mself\u001b[39m._size - \u001b[38;5;28mself\u001b[39m._loc\n\u001b[32m--> \u001b[39m\u001b[32m521\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fetch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_loc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_loc\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    522\u001b[39m out: \u001b[38;5;28mbytes\u001b[39m = \u001b[38;5;28mself\u001b[39m._cache[\u001b[38;5;28mself\u001b[39m._loc - \u001b[38;5;28mself\u001b[39m._start : \u001b[38;5;28mself\u001b[39m._loc - \u001b[38;5;28mself\u001b[39m._start + length]\n\u001b[32m    523\u001b[39m \u001b[38;5;28mself\u001b[39m._loc += \u001b[38;5;28mlen\u001b[39m(out)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/yochlol/lib/python3.11/site-packages/awswrangler/s3/_fs.py:367\u001b[39m, in \u001b[36m_S3ObjectBase._fetch\u001b[39m\u001b[34m(self, start, end)\u001b[39m\n\u001b[32m    365\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m new_block_end > \u001b[38;5;28mself\u001b[39m._end:\n\u001b[32m    366\u001b[39m     prune_diff: \u001b[38;5;28mint\u001b[39m = new_block_start - \u001b[38;5;28mself\u001b[39m._start\n\u001b[32m--> \u001b[39m\u001b[32m367\u001b[39m     \u001b[38;5;28mself\u001b[39m._cache = \u001b[38;5;28mself\u001b[39m._cache[prune_diff:] + \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fetch_range_proxy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_end\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_block_end\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m new_block_start < \u001b[38;5;28mself\u001b[39m._start:\n\u001b[32m    369\u001b[39m     prune_diff = new_block_end - \u001b[38;5;28mself\u001b[39m._end\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/yochlol/lib/python3.11/site-packages/awswrangler/s3/_fs.py:280\u001b[39m, in \u001b[36m_S3ObjectBase._fetch_range_proxy\u001b[39m\u001b[34m(self, start, end)\u001b[39m\n\u001b[32m    278\u001b[39m range_size: \u001b[38;5;28mint\u001b[39m = end - start\n\u001b[32m    279\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cpus < \u001b[32m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m range_size < (\u001b[32m2\u001b[39m * _MIN_PARALLEL_READ_BLOCK):\n\u001b[32m--> \u001b[39m\u001b[32m280\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_fetch_range\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrange_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbucket\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bucket\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m        \u001b[49m\u001b[43ms3_client\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[43m        \u001b[49m\u001b[43mboto3_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mboto3_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[43m        \u001b[49m\u001b[43mversion_id\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_version_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m    288\u001b[39m sizes: \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mint\u001b[39m, ...] = _utils.get_even_chunks_sizes(\n\u001b[32m    289\u001b[39m     total_size=range_size, chunk_size=_MIN_PARALLEL_READ_BLOCK, upper_bound=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    290\u001b[39m )\n\u001b[32m    291\u001b[39m ranges: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]] = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/yochlol/lib/python3.11/site-packages/awswrangler/s3/_fs.py:75\u001b[39m, in \u001b[36m_fetch_range\u001b[39m\u001b[34m(range_values, bucket, key, s3_client, boto3_kwargs, version_id)\u001b[39m\n\u001b[32m     64\u001b[39m     boto3_kwargs[\u001b[33m\"\u001b[39m\u001b[33mVersionId\u001b[39m\u001b[33m\"\u001b[39m] = version_id\n\u001b[32m     65\u001b[39m resp = _utils.try_it(\n\u001b[32m     66\u001b[39m     f=s3_client.get_object,\n\u001b[32m     67\u001b[39m     ex=_S3_RETRYABLE_ERRORS,\n\u001b[32m   (...)\u001b[39m\u001b[32m     73\u001b[39m     **boto3_kwargs,\n\u001b[32m     74\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m start, \u001b[43mresp\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mBody\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/yochlol/lib/python3.11/site-packages/botocore/response.py:99\u001b[39m, in \u001b[36mStreamingBody.read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Read at most amt bytes from the stream.\u001b[39;00m\n\u001b[32m     95\u001b[39m \n\u001b[32m     96\u001b[39m \u001b[33;03mIf the amt argument is omitted, read all data.\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     chunk = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raw_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m URLLib3ReadTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    101\u001b[39m     \u001b[38;5;66;03m# TODO: the url will be None as urllib3 isn't setting it yet\u001b[39;00m\n\u001b[32m    102\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeoutError(endpoint_url=e.url, error=e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/yochlol/lib/python3.11/site-packages/urllib3/response.py:955\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt, decode_content, cache_content)\u001b[39m\n\u001b[32m    952\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) >= amt:\n\u001b[32m    953\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._decoded_buffer.get(amt)\n\u001b[32m--> \u001b[39m\u001b[32m955\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    957\u001b[39m flush_decoder = amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[32m    959\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/yochlol/lib/python3.11/site-packages/urllib3/response.py:879\u001b[39m, in \u001b[36mHTTPResponse._raw_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    876\u001b[39m fp_closed = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._fp, \u001b[33m\"\u001b[39m\u001b[33mclosed\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    878\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._error_catcher():\n\u001b[32m--> \u001b[39m\u001b[32m879\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[32m    882\u001b[39m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    887\u001b[39m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[32m    888\u001b[39m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[32m    889\u001b[39m         \u001b[38;5;28mself\u001b[39m._fp.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/yochlol/lib/python3.11/site-packages/urllib3/response.py:862\u001b[39m, in \u001b[36mHTTPResponse._fp_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    859\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read1()\n\u001b[32m    860\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    861\u001b[39m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m862\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/yochlol/lib/python3.11/http/client.py:481\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    479\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    480\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m481\u001b[39m         s = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_safe_read\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    482\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m IncompleteRead:\n\u001b[32m    483\u001b[39m         \u001b[38;5;28mself\u001b[39m._close_conn()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/yochlol/lib/python3.11/http/client.py:630\u001b[39m, in \u001b[36mHTTPResponse._safe_read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    623\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_safe_read\u001b[39m(\u001b[38;5;28mself\u001b[39m, amt):\n\u001b[32m    624\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Read the number of bytes requested.\u001b[39;00m\n\u001b[32m    625\u001b[39m \n\u001b[32m    626\u001b[39m \u001b[33;03m    This function should be used when <amt> bytes \"should\" be present for\u001b[39;00m\n\u001b[32m    627\u001b[39m \u001b[33;03m    reading. If the bytes are truly not available (due to EOF), then the\u001b[39;00m\n\u001b[32m    628\u001b[39m \u001b[33;03m    IncompleteRead exception can be used to detect the problem.\u001b[39;00m\n\u001b[32m    629\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m630\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.fp.read(amt)\n\u001b[32m    631\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) < amt:\n\u001b[32m    632\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(data, amt-\u001b[38;5;28mlen\u001b[39m(data))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/yochlol/lib/python3.11/socket.py:705\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    703\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    704\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m705\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    706\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    707\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/yochlol/lib/python3.11/ssl.py:1278\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1274\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1275\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1276\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1277\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1278\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1279\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1280\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/yochlol/lib/python3.11/ssl.py:1134\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1132\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1133\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1134\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1135\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1136\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def define_unique_groups(df, column=\"video_filename\"):\n",
    "    \"\"\"Define grouby object and uniques, useful idiom for dataframe loop operations.\"\"\"\n",
    "    uniques = df[column].unique()\n",
    "    grouped = df.groupby(column)\n",
    "    return uniques, grouped\n",
    "\n",
    "\n",
    "def label_dist(df, col=\"final_label\"):\n",
    "    #print(df.drop_duplicates('unique_id')[col].value_counts(dropna=False).sort_index())\n",
    "    print(df.drop_duplicates('session_id')[col].value_counts(dropna=False).sort_index())\n",
    "\n",
    "\n",
    "# load Qualtrics from aws wrangler or athena or parquet\n",
    "def query_ptsd_data(query=None, database=None, debug=False) -> pd.DataFrame:\n",
    "    if debug:\n",
    "        # Limit query to be very small (thus fast)\n",
    "        query = \"SELECT DISTINCT * FROM cv LIMIT 100\"\n",
    "\n",
    "    if query is None:\n",
    "        query = insight_config.QUERY\n",
    "\n",
    "    if database is None:\n",
    "        database = insight_config.DATABASE\n",
    "\n",
    "\n",
    "    if insight_config.VERBOSE:\n",
    "        print(\"Querying Athena database, this can take a few minutes...\")\n",
    "        # TODO: add progress bar/estimator\n",
    "    df = wr.athena.read_sql_query(\n",
    "        query, database=database, ctas_approach=True, chunksize=True\n",
    "    )\n",
    "    # NOTE: Times out for some users, chunksize=True returns tables in a flexible way, by\n",
    "    # splitting the data in a Iterable of DataFrames (Memory friendly).\n",
    "    # If True awswrangler iterates on the data by files in the most efficient way without\n",
    "    # guarantee of chunksize.\"\n",
    "\n",
    "    # concat the generator of dataframes returned by chunksize=True\n",
    "    df = pd.concat(df, axis=0)\n",
    "\n",
    "    df = df.sort_values(\n",
    "        by=[\"session_id\", \"video_filename\", \"row_number\"], ignore_index=True\n",
    "    )\n",
    "\n",
    "    # Remove test samples\n",
    "    new_df = df[\n",
    "        ~df[\"session_id\"].str.contains(insight_config.TEST_SAMPLES)\n",
    "    ].reset_index(drop=True)\n",
    "\n",
    "    if insight_config.VERBOSE:\n",
    "        print(f\"Query returned df shape {new_df.shape}\")\n",
    "\n",
    "    save_query_df(new_df)\n",
    "\n",
    "    return new_df\n",
    "\n",
    "\n",
    "def dataset_stats(df, target=\"ptsd\"):\n",
    "    \"\"\"Return unique people, sessions, and class balance stats.\"\"\"\n",
    "    num_people = df[\"unique_id\"].nunique()\n",
    "\n",
    "    if \"session_id\" in df.columns.to_list():\n",
    "        num_sessions = df[\"session_id\"].nunique()\n",
    "    else:\n",
    "        num_sessions = np.nan\n",
    "\n",
    "    # Return pd.Series of target labels by person (\"unique_id\")\n",
    "    # TODO: also consider by \"session_id\"\n",
    "    class_balance = df.drop_duplicates(\"unique_id\")[target].value_counts().sort_index()\n",
    "    return num_people, num_sessions, class_balance\n",
    "\n",
    "\n",
    "def print_dataset_stats(num_people, num_sessions, class_balance):\n",
    "    \"\"\"Convenience to hide a bunch of printing in a function.\n",
    "    Useful to know during exploration & data ingestion.\"\"\"\n",
    "    print(\"---------------------------------\")\n",
    "    print(f\"Unique People: {num_people}\")\n",
    "    print(f\"Num Sessions: {num_sessions}\")\n",
    "    print(f\"Class balance:\\n{class_balance}\")\n",
    "    print(\"---------------------------------\")\n",
    "\n",
    "\n",
    "# Qualtrics\n",
    "#QUERY = \"select * from data_quality.qualtrics_surveys_mp\"\n",
    "#QUERY = \"select * from data_quality.qualtrics_surveys_mp_1st_cohort\"\n",
    "QUERY = \"select * from data_quality.qualtrics_surveys_unified\"\n",
    "DATABASE = \"data_quality\"\n",
    "df = wr.athena.read_sql_query(QUERY, database=DATABASE, ctas_approach=True, chunksize=True)\n",
    "# concat the generator of dataframes returned by chunksize=True\n",
    "dfq = pd.concat(df, axis=0)\n",
    "\n",
    "# df = df.sort_values(\n",
    "#     by=[\"session_id\", \"video_filename\", \"row_number\"], ignore_index=True\n",
    "# )\n",
    "\n",
    "# PCL processed\n",
    "QUERY = \"select * from data_quality.mp_pcl_scores\"\n",
    "DATABASE = \"data_quality\"\n",
    "df = wr.athena.read_sql_query(QUERY, database=DATABASE, ctas_approach=True, chunksize=True)\n",
    "dx = pd.concat(df, axis=0)\n",
    "\n",
    "\n",
    "# Hermit CV & Events\n",
    "#QUERY = \"select * from data_quality.messy_prototyping_app_session_details where session_id = 'd0c300d6-8a13-42f2-b838-fdba7416a6ad_1746571332071'\"\n",
    "QUERY = \"select * from data_quality.messy_prototyping_app_session_details\"\n",
    "DATABASE = \"data_quality\"\n",
    "df = wr.athena.read_sql_query(QUERY, database=DATABASE, ctas_approach=True, chunksize=True)\n",
    "# concat the generator of dataframes returned by chunksize=True\n",
    "dfcve = pd.concat(df, axis=0)\n",
    "dfcve['unique_id'] = dfcve['session_id'].apply(lambda x: x.split('_')[0])\n",
    "\n",
    "\n",
    "# Quality stuff\n",
    "QUERY = \"select session_id, problem from data_quality.master_query_session_completion_check where problem = 'none' and study_location = 'Messy Prototyping'\"\n",
    "DATABASE = \"data_quality\"\n",
    "df = wr.athena.read_sql_query(QUERY, database=DATABASE, ctas_approach=True, chunksize=True)\n",
    "df_quality = pd.concat(df, axis=0)\n",
    "# df = df.sort_values(\n",
    "#     by=[\"session_id\", \"video_filename\", \"row_number\"], ignore_index=True\n",
    "# )\n",
    "\n",
    "\n",
    "# Check that qualtrics and CV/events are equal size\n",
    "try:\n",
    "    assert dfq['order_uuid'].nunique() == dfq['session_id'].nunique(), \"Unequal session & order id\"\n",
    "except AssertionError as e:\n",
    "    if dfq['order_uuid'].nunique() < dfq['session_id'].nunique():\n",
    "        print(\"More sessions than order ids. Repeat sessions?\")\n",
    "assert dfcve['session_id'].nunique() == dfcve['session_id'].nunique(), \"Unequal session & order id\"\n",
    "assert dx['session_id'].nunique() == dx['session_id'].nunique(), \"Unequal session & order id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee29e1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV & PCL intersection: 267\n",
      "+ Qualtrics: 267\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ptsd_bin\n",
       "0    126\n",
       "1    141\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sessions_to_use = df_quality['session_id'].unique().tolist()\n",
    "\n",
    "\n",
    "dfq = dfq[dfq['session_id'].isin(sessions_to_use)].reset_index(drop=True)\n",
    "dfcve = dfcve[dfcve['session_id'].isin(sessions_to_use)].reset_index(drop=True)\n",
    "dx = dx[dx['session_id'].isin(sessions_to_use)].reset_index(drop=True)\n",
    "\n",
    "# Filter intersection of all 3\n",
    "q, c, x = dfq['session_id'].unique(), dfcve['session_id'].unique(), dx['session_id'].unique()\n",
    "q, c, x = set(q), set(c), set(x)\n",
    "intersection = c & x\n",
    "print(f\"CV & PCL intersection: {len(intersection)}\")\n",
    "final_session_list = list(q & intersection)\n",
    "print(f\"+ Qualtrics: {len(final_session_list)}\")\n",
    "\n",
    "dfq = dfq[dfq['session_id'].isin(final_session_list)].reset_index(drop=True)\n",
    "dfcve = dfcve[dfcve['session_id'].isin(final_session_list)].reset_index(drop=True)\n",
    "dx = dx[dx['session_id'].isin(final_session_list)].reset_index(drop=True)\n",
    "\n",
    "assert dfq['session_id'].nunique() == dfcve['session_id'].nunique() == dx['session_id'].nunique()\n",
    "\n",
    "# Binary labels\n",
    "dx['ptsd_bin'] = dx['ptsd'].map({\"Negative\": 0, \"Positive\": 1})\n",
    "dx['ptsd_bin'].value_counts(dropna=False)\n",
    "\n",
    "dx['pcl_score'].hist(bins=20)\n",
    "plt.show()\n",
    "\n",
    "dx['ptsd_bin'].value_counts(dropna=False).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92ac5a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "REMOVE_INTERMEDIATE = False # True\n",
    "PTSD_THRESHOLD = 33\n",
    "BUFFER = 8 # 8 = (25, 41)\n",
    "\n",
    "if REMOVE_INTERMEDIATE:\n",
    "    dxx = dx[~dx['pcl_score'].between(PTSD_THRESHOLD-BUFFER, PTSD_THRESHOLD+BUFFER, inclusive='both')]\n",
    "    print(dxx['ptsd_bin'].value_counts(dropna=False).sort_index())\n",
    "\n",
    "    dxx['pcl_score'].hist(bins=20)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# TODO: apply to actual dx and filter if you want to go this way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3a12c3",
   "metadata": {},
   "source": [
    "### survey wrangling (LEC, depression, anxiety, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90f884e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf73045a",
   "metadata": {},
   "source": [
    "### CV & event wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5467043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: drop List Learning / .m4a / audio from dataframe, it has no CV/timeseries\n",
    "idx_LL = dfcve['task_id'].str.contains(\"list_learning\")\n",
    "dfcve = dfcve[~idx_LL]\n",
    "# TODO: replace later with tabular data\n",
    "\n",
    "# Order\n",
    "dfcve = dfcve.sort_values(by=['session_id', 'frametimestamps']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5aee5193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16253257, 42), 267)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfcve.shape, dfcve['session_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fac6ec6",
   "metadata": {},
   "source": [
    "##### grab phone info (no 12, no minis) SKIP if error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c17c6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab phone model & app version and join with cv/events\n",
    "#QUERY = \"select * from data_quality.messy_prototyping_tracker\" # error prone `QueryFailed: INVALID_CAST_ARGUMENT`, `user` BIGINT issue\n",
    "QUERY = \"select session_id, version_name, phone_model from data_quality.messy_prototyping_tracker\"\n",
    "DATABASE = \"data_quality\"\n",
    "\n",
    "#df = wr.athena.read_sql_query(QUERY, database=DATABASE, ctas_approach=True, chunksize=True)\n",
    "df = wr.athena.read_sql_query(QUERY, database=DATABASE, ctas_approach=False, chunksize=True)\n",
    "db = pd.concat(df, axis=0)\n",
    "\n",
    "# strip to only match sessions; cary over specific columns\n",
    "db = db[db['session_id'].isin(final_session_list)][['session_id', 'phone_model', 'version_name']]\n",
    "\n",
    "EXCLUDE_PHONES = [\"?unrecognized?\", \"iPhone 13 Mini\"]\n",
    "db = db[~db['phone_model'].isin(EXCLUDE_PHONES)]\n",
    "db = db[~db['phone_model'].str.contains(\"Mini\")]\n",
    "\n",
    "# merge phone type with event/cv df\n",
    "dfcve = db.merge(dfcve, how='inner', on='session_id').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4db7037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15976422, 44), 262)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_session_list = dfcve['session_id'].unique()\n",
    "dfcve.shape, dfcve['session_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7fa161",
   "metadata": {},
   "source": [
    "### rename tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1b75742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse task name unifier\n",
    "\n",
    "def get_task_names_map():\n",
    "    \"\"\"Return mapping use to unify various names for each task\"\"\"\n",
    "    return {\n",
    "        # \"plr_view\": \"plr\",\n",
    "        # \"PLR\": \"plr\",\n",
    "        \"aiv\": \"affective_image_set\",\n",
    "        \"ptsd_image_set\": \"affective_image_set\",\n",
    "    }\n",
    "\n",
    "\n",
    "def fix_task_names(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Returns df with new task_id_renamed column with old intact.\n",
    "\n",
    "    Effectively, removes block numbers and other inconsistent naming practices.\n",
    "    \"\"\"\n",
    "\n",
    "    task_dict = get_task_names_map()\n",
    "    new_df = df.copy()\n",
    "\n",
    "    # Must create new column each renaming step.\n",
    "    # Re-running on same column overwrites ALL values, effectively only running that line\n",
    "    new_df[\"renamed_0\"] = new_df[\"task_id\"].str.replace( # plr_x -> plr\n",
    "        r\".*plr.*\", \"plr\", flags=re.IGNORECASE, regex=True\n",
    "    )\n",
    "    new_df[\"renamed_1\"] = new_df[\"renamed_0\"].replace(task_dict) # tasks in task dict\n",
    "    new_df[\"renamed_2\"] = new_df[\"renamed_1\"].str.replace( # aiv block removal\n",
    "        r\".*affective.*\", \"affective_image_set\", regex=True\n",
    "    )\n",
    "    new_df[\"renamed_3\"] = new_df[\"renamed_2\"].str.replace(\n",
    "        r\".*face_pairs.*\", \"face_pairs\", regex=True\n",
    "    )\n",
    "    new_df[\"renamed_4\"] = new_df[\"renamed_3\"].str.replace(\n",
    "        r\".*mckinnon.*\", \"mckinnon\", regex=True\n",
    "    )\n",
    "    new_df[\"renamed_5\"] = new_df[\"renamed_4\"].str.replace(\n",
    "        r\".*list_learning.*\", \"list_learning\", regex=True\n",
    "    )\n",
    "\n",
    "    new_df[\"task_id_renamed\"] = new_df[\"renamed_5\"].str.replace(\n",
    "        r\".*attention.*\", \"attention_bias\", flags=re.IGNORECASE, regex=True\n",
    "    )\n",
    "    # TODO: check other dot stuff like events\n",
    "\n",
    "\n",
    "    del new_df[\"renamed_0\"]\n",
    "    del new_df[\"renamed_1\"]\n",
    "    del new_df[\"renamed_2\"]\n",
    "    del new_df[\"renamed_3\"]\n",
    "    del new_df[\"renamed_4\"]\n",
    "    del new_df[\"renamed_5\"]\n",
    "\n",
    "    # Test for misses (additional tasks beyond this will result in False)\n",
    "    REFERENCE = [\n",
    "        \"plr\",\n",
    "        \"calibration_1\",\n",
    "        \"calibration_2\",\n",
    "        # \"attention_bias\",\n",
    "        \"face_pairs\",\n",
    "        # \"affective_image_set\",\n",
    "        \"mckinnon\",\n",
    "        \"list_learning\"\n",
    "    ]\n",
    "    tasks = new_df[\"task_id_renamed\"].value_counts().index.to_list()\n",
    "    assert all(t in REFERENCE for t in tasks)\n",
    "\n",
    "    return new_df\n",
    "\n",
    "dfcve2 = fix_task_names(dfcve)\n",
    "dfcve2 = dfcve2.dropna(subset='frametimestamps', axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8efa1816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15953350, 45), 262)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfcve2.shape, dfcve2['session_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9acdb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_nans(series: pd.Series):\n",
    "    return (series.isna()).sum() == 0\n",
    "\n",
    "# nan check\n",
    "assert no_nans(dfcve2['session_id'])\n",
    "#assert no_nans(dfcve2['video_path'])\n",
    "assert no_nans(dfcve2['row_number']) # bypass\n",
    "assert no_nans(dfcve2['frametimestamps'])\n",
    "\n",
    "#sorted_df = dfcve2.sort_values(by=['session_id', 'frametimestamps']) # already sorted, pushed nans to end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a4d234",
   "metadata": {},
   "source": [
    "#### encode tasks (skip for now)\n",
    "(once Michael C's work is integrated across qualtrics, UI, and Research/`dot`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7edff403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "cols = [\n",
    "    \"task_id\",\n",
    "    \"event_name\",\n",
    "    \"event_type\",\n",
    "    \"condition\",\n",
    "    \"top_emotion\",\n",
    "    \"bottom_emotion\",\n",
    "    \"cue_location\",\n",
    "    \"dot_location\",\n",
    "    \"incongruency\",\n",
    "    \"engage_disengage\",\n",
    "]\n",
    "\n",
    "# # time wtf: row_number, timestamps can be out of order,.... why?\n",
    "\n",
    "# # TODO:\n",
    "# # / handcrafted\n",
    "# # / one hot\n",
    "# # / assign to df wrangling\n",
    "# # - match prod col names/organization\n",
    "\n",
    "# various_time_cols = [  # for reference. delete once built\n",
    "#     \"frame_timestamps\",\n",
    "#     \"frametimestamps\",\n",
    "#     \"video_frametimestamps\",\n",
    "#     \"row_number\",\n",
    "# ]\n",
    "\n",
    "# ONEHOT_MAP = {  # for ref\n",
    "#     \"task\": [0, 1, 2, 3],  # cal, plr, mab, mck\n",
    "#     \"mab_engagement / mck_phase\": [0, 1, 2],\n",
    "#     \"mab_emotion / mck_emotion\": [0, 1, 2, 3],\n",
    "#     \"mab_emo_location / mck subcat\": [0, 1],\n",
    "#     \"mab_dot_location\": [0, 1],\n",
    "#     \"mab_cue_location\": [0, 1],\n",
    "# }\n",
    "\n",
    "\n",
    "def encode_task_handcrafted(df: pd.DataFrame, task=\"mab\") -> np.array:\n",
    "    df = df[df[\"task\"] == task].copy()\n",
    "    print(df)\n",
    "    n_rows = df.shape[0]\n",
    "\n",
    "    # maps\n",
    "    MAB_MAP = {\n",
    "        \"engagement\": {\"disengagement\": 0, \"engagement\": 1},\n",
    "        \"emotion\": {\"neutral\": 0, \"happy\": 1, \"sad\": 2, \"angry\": 3},\n",
    "        \"emo_location\": {\"bottom\": 0, \"top\": 1},\n",
    "        \"dot_location\": {\"bottom\": 0, \"top\": 1},\n",
    "        \"cue_location\": {\"bottom\": 0, \"top\": 1},\n",
    "    }\n",
    "\n",
    "    MCKINNON_MAP = {\n",
    "        \"phase\": {\"fixation\": 0, \"image\": 1, \"blank\": 2},\n",
    "        \"emotion\": {\"positive\": 0, \"negative\": 1, \"neutral\": 2, \"negative_arousal\": 3},\n",
    "        \"subcategory\": {},\n",
    "    }\n",
    "\n",
    "    # checks\n",
    "    def check_length(encoding, n_rows):\n",
    "        return encoding.shape[0] == n_rows\n",
    "\n",
    "    # parse task\n",
    "    match task:\n",
    "        case \"calibration\":\n",
    "            enc = np.zeros(6, dtype=np.uint8)\n",
    "            enc = np.tile(enc, (n_rows, 1))\n",
    "            assert check_length(enc, n_rows)\n",
    "            return enc\n",
    "\n",
    "        case \"plr\":\n",
    "            enc = np.zeros(6, dtype=np.uint8)\n",
    "            enc[0] = 1\n",
    "            enc = np.tile(enc, (n_rows, 1))\n",
    "            assert check_length(enc, n_rows)\n",
    "            return enc\n",
    "\n",
    "        case \"mab\":\n",
    "            enc = np.zeros(6, dtype=np.uint8)\n",
    "            enc[0] = 2\n",
    "            enc = np.tile(enc, (n_rows, 1))\n",
    "            enc[:, 1] = df[\"mab_engagement\"].apply(lambda x: MAB_MAP[\"engagement\"][x])\n",
    "            enc[:, 2] = df[\"mab_emotion\"].apply(lambda x: MAB_MAP[\"emotion\"][x])\n",
    "            enc[:, 3] = df[\"mab_emo_location\"].apply(\n",
    "                lambda x: MAB_MAP[\"emotion_location\"][x]\n",
    "            )\n",
    "            enc[:, 4] = df[\"mab_dot_location\"].apply(\n",
    "                lambda x: MAB_MAP[\"dot_location\"][x]\n",
    "            )\n",
    "            enc[:, 5] = df[\"mab_cue_location\"].apply(\n",
    "                lambda x: MAB_MAP[\"cue_location\"][x]\n",
    "            )\n",
    "            assert check_length(enc, n_rows)\n",
    "            return enc\n",
    "\n",
    "        case \"mckinnon\":\n",
    "            enc = np.zeros(6, dtype=np.uint8)\n",
    "            enc[0] = 3\n",
    "            enc = np.tile(enc, (n_rows, 1))\n",
    "            enc[:, 1] = df[\"mck_phase\"].apply(lambda x: MCKINNON_MAP[\"phase\"][x])\n",
    "            enc[:, 2] = df[\"mck_emotion\"].apply(lambda x: MCKINNON_MAP[\"emotion\"][x])\n",
    "            # enc[:, 3] = df[\"mck_subcategory\"].apply(lambda x: MCKINNON_MAP[\"subcategory\"][x])\n",
    "            assert check_length(enc, n_rows)\n",
    "            return enc\n",
    "\n",
    "        case _:\n",
    "            raise ValueError(f\"'{task}' task not recognized\")\n",
    "\n",
    "\n",
    "def encode_task_onehot(df: pd.DataFrame, task=\"mab\") -> pd.DataFrame:\n",
    "    df = df[df[\"task\"] == task].copy()\n",
    "    n_rows = df.shape[0]\n",
    "\n",
    "    # checks\n",
    "    def check_length(encoding, n_rows):\n",
    "        return encoding.shape[0] == n_rows\n",
    "\n",
    "    # maps\n",
    "    MAB_MAP = {\n",
    "        \"engagement\": {\"disengagement\": 0, \"engagement\": 1},\n",
    "        \"emotion\": {\"neutral\": 0, \"happy\": 1, \"sad\": 2, \"angry\": 3},\n",
    "        \"emotion_location\": {\"bottom\": 0, \"top\": 1},\n",
    "        \"dot_location\": {\"bottom\": 0, \"top\": 1},\n",
    "        \"cue_location\": {\"bottom\": 0, \"top\": 1},\n",
    "    }\n",
    "\n",
    "    task_1hot = OneHotEncoder(\n",
    "        categories=[[\"calibration\", \"plr\", \"mab\", \"mckinnon\"]], sparse_output=False\n",
    "    )\n",
    "\n",
    "    # parse task\n",
    "    match task:\n",
    "        case \"calibration\":\n",
    "            # init 1hot dataframe\n",
    "            output_columns = pd.DataFrame(columns=[\"task_1hot\"])\n",
    "            # set task column first\n",
    "            output = task_1hot.fit_transform(df[\"task\"].values.reshape(-1, 1))\n",
    "            output = pd.Series(list(output))\n",
    "            output_columns[\"task_1hot\"] = output\n",
    "            # reindex to match for merging\n",
    "            output_columns = output_columns.set_index(df.index)\n",
    "            assert check_length(output_columns, n_rows)\n",
    "            return output_columns\n",
    "\n",
    "        case \"plr\":\n",
    "            # init 1hot dataframe\n",
    "            output_columns = pd.DataFrame(columns=[\"task_1hot\"])\n",
    "            # set task column first\n",
    "            output = task_1hot.fit_transform(df[\"task\"].values.reshape(-1, 1))\n",
    "            output = pd.Series(list(output))\n",
    "            output_columns[\"task_1hot\"] = output\n",
    "            # reindex to match for merging\n",
    "            output_columns = output_columns.set_index(df.index)\n",
    "            assert check_length(output_columns, n_rows)\n",
    "            return output_columns\n",
    "\n",
    "        case \"mab\":\n",
    "            encoders = {\n",
    "                \"mab_engagement\": OneHotEncoder(\n",
    "                    categories=[[\"disengagement\", \"engagement\"]], sparse_output=False\n",
    "                ),\n",
    "                \"mab_emotion\": OneHotEncoder(\n",
    "                    categories=[[\"neutral\", \"happy\", \"sad\", \"angry\"]],\n",
    "                    sparse_output=False,\n",
    "                ),\n",
    "                \"mab_emo_location\": OneHotEncoder(\n",
    "                    categories=[[\"bottom\", \"top\"]], sparse_output=False\n",
    "                ),\n",
    "                \"mab_dot_location\": OneHotEncoder(\n",
    "                    categories=[[\"bottom\", \"top\"]], sparse_output=False\n",
    "                ),\n",
    "                \"mab_cue_location\": OneHotEncoder(\n",
    "                    categories=[[\"bottom\", \"top\"]], sparse_output=False\n",
    "                ),\n",
    "            }\n",
    "\n",
    "            # init 1hot dataframe\n",
    "            col_list = list(encoders.keys())\n",
    "            col_list.insert(0, \"task_1hot\")\n",
    "            output_columns = pd.DataFrame(columns=col_list)\n",
    "\n",
    "            # set task column first\n",
    "            output = task_1hot.fit_transform(df[\"task\"].values.reshape(-1, 1))\n",
    "            output = pd.Series(list(output))\n",
    "            output_columns[\"task_1hot\"] = output\n",
    "\n",
    "            # loop through the other hierarchical 1hot encoders and add to columns\n",
    "            for col, encoder in encoders.items():\n",
    "                output = encoder.fit_transform(df[col].values.reshape(-1, 1))\n",
    "                output = pd.Series(list(output))\n",
    "                output_columns[col + \"_1hot\"] = output\n",
    "                del output_columns[col]\n",
    "            output_columns = output_columns.set_index(df.index)\n",
    "            assert check_length(output_columns, n_rows)\n",
    "            return output_columns\n",
    "\n",
    "        case \"mckinnon\":\n",
    "            encoders = {\n",
    "                \"mck_phase\": OneHotEncoder(\n",
    "                    categories=[[\"fixation\", \"image\", \"blank\"]], sparse_output=False\n",
    "                ),\n",
    "                \"mck_emotion\": OneHotEncoder(\n",
    "                    categories=[\n",
    "                        [\"positive\", \"negative\", \"neutral\", \"negative_arousal\"]\n",
    "                    ],\n",
    "                    sparse_output=False,\n",
    "                ),\n",
    "                # \"mck_subcategory\": OneHotEncoder(\n",
    "                #     categories=[[\"\"]], sparse_output=False\n",
    "                # ),\n",
    "            }\n",
    "\n",
    "            # init 1hot dataframe\n",
    "            col_list = list(encoders.keys())\n",
    "            col_list.insert(0, \"task_1hot\")\n",
    "            output_columns = pd.DataFrame(columns=col_list)\n",
    "\n",
    "            # set task column first\n",
    "            output = task_1hot.fit_transform(df[\"task\"].values.reshape(-1, 1))\n",
    "            output = pd.Series(list(output))\n",
    "            output_columns[\"task_1hot\"] = output\n",
    "\n",
    "            # loop through the other hierarchical 1hot encoders and add to columns\n",
    "            for col, encoder in encoders.items():\n",
    "                output = encoder.fit_transform(df[col].values.reshape(-1, 1))\n",
    "                output = pd.Series(list(output))\n",
    "                output_columns[col + \"_1hot\"] = output\n",
    "                del output_columns[col]\n",
    "            output_columns = output_columns.set_index(df.index)\n",
    "            assert check_length(output_columns, n_rows)\n",
    "            return output_columns\n",
    "\n",
    "        case _:\n",
    "            raise ValueError(f\"'{task}' task not recognized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf6fec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# EXAMPLE USE - SETUP\n",
    "\n",
    "task_cols = [\n",
    "    \"task\",\n",
    "    \"mab_engagement\",\n",
    "    \"mab_emotion\",\n",
    "    \"mab_emo_location\",\n",
    "    \"mab_dot_location\",\n",
    "    \"mab_cue_location\",\n",
    "    \"mck_phase\",\n",
    "    \"mck_emotion\",\n",
    "]\n",
    "\n",
    "task_df = df[task_cols].copy()\n",
    "# print(task_df)\n",
    "\n",
    "# df[\"task_encoding\"] = encode_task_handcrafted(task_df, task=\"task\")\n",
    "\n",
    "# # ----- HANDCRAFTED -----\n",
    "# task_df[\"task_encoding\"] = np.nan\n",
    "# task_df[\"task_encoding\"] = task_df[\"task_encoding\"].astype(object)\n",
    "\n",
    "# enc_vector = encode_task_handcrafted(task_df, task=TASK)\n",
    "# mask = task_df[\"task\"] == TASK\n",
    "# assert mask.sum() == enc_vector.shape[0]\n",
    "\n",
    "# # Assign row by row (inefficient but ok loop)\n",
    "# # for idx, encoding in zip(task_df[mask].index, enc_vector):\n",
    "# #     task_df.at[idx, \"task_encoding\"] = encoding\n",
    "\n",
    "# # Pandas idiomatic (better assuming indexes align...)\n",
    "# enc_series = pd.Series(list(enc_vector), index=task_df[mask].index)\n",
    "# task_df.loc[enc_series.index, \"task_encoding\"] = enc_series\n",
    "# print(task_df)\n",
    "\n",
    "\n",
    "    # ----- ONEHOT -----\n",
    "print(task_df)\n",
    "\n",
    "enc_df = encode_task_onehot(task_df, task=\"mab\")\n",
    "print(enc_df)\n",
    "\n",
    "# NOTE: replace task_df with original df once tested\n",
    "\n",
    "# NOTE: MAB & McKinnon only\n",
    "for col in enc_df.columns:\n",
    "    if col not in task_df.columns:\n",
    "        task_df[col] = pd.NA\n",
    "task_df.update(enc_df, overwrite=False, errors=\"raise\")\n",
    "print(task_df)\n",
    "print(task_df[\"task_1hot\"])\n",
    "\n",
    "enc_df = encode_task_onehot(task_df, task=\"calibration\")\n",
    "print(enc_df)\n",
    "task_df.update(enc_df, overwrite=False, errors=\"raise\")\n",
    "print(task_df)\n",
    "print(task_df[\"task_1hot\"])\n",
    "\n",
    "enc_df = encode_task_onehot(task_df, task=\"plr\")\n",
    "print(enc_df)\n",
    "task_df.update(enc_df, overwrite=False, errors=\"raise\")\n",
    "print(task_df)\n",
    "print(task_df[\"task_1hot\"])\n",
    "\n",
    "enc_df = encode_task_onehot(task_df, task=\"mckinnon\")\n",
    "print(enc_df)\n",
    "# NOTE: MAB & McKinnon only\n",
    "for col in enc_df.columns:\n",
    "    if col not in task_df.columns:\n",
    "        task_df[col] = pd.NA\n",
    "task_df.update(enc_df, overwrite=False, errors=\"raise\")\n",
    "print(task_df)\n",
    "print(task_df[[\"mck_phase\", \"mck_emotion\", \"mck_phase_1hot\", \"mck_emotion_1hot\"]])\n",
    "print(task_df[\"task_1hot\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e87d5af",
   "metadata": {},
   "source": [
    "## check final cv df after cleaning, task renaming & encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb5b9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfcve2.shape, dfcve2['session_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78e2c53",
   "metadata": {},
   "source": [
    "## merge targets/surveys with cv & events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a0f0182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15953350, 47) 262\n",
      "ptsd_bin\n",
      "0    124\n",
      "1    138\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "labels = dx[['session_id', 'pcl_score', 'ptsd_bin']]\n",
    "\n",
    "df = labels.merge(dfcve2, how='inner', on='session_id')\n",
    "\n",
    "print(df.shape, df['session_id'].nunique())\n",
    "#df.drop_duplicates('session_id')['ptsd_bin'].value_counts(dropna=False)\n",
    "label_dist(df, col='ptsd_bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990a80af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO NEXT: remove first 3000ms of \"get ready\" (CAN'T BE BASED ON FPS, BUT TIME)\n",
    "#CHOP_OFF_ms = 3000  # first 3000 ms are \"get ready\", or `event_name``\n",
    "df2 = df[~df['event_name'].str.contains(\"get ready\")].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd8f9f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ptsd_bin\n",
      "0    124\n",
      "1    138\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((15472232, 47), 262, None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape, df2['session_id'].nunique(), label_dist(df2, col='ptsd_bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fca203",
   "metadata": {},
   "source": [
    "# SKIP & LOAD\n",
    "start here to load a processed parquet file and skip the queries (262 sessions as of 2025-06-23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa0654cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import fireducks.pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mplcyberpunk\n",
    "plt.style.use('cyberpunk')\n",
    "from tqdm import tqdm\n",
    "import awswrangler as wr\n",
    "#from flaml import AutoML\n",
    "\n",
    "# import dask.array as da\n",
    "# import dask.dataframe as dd\n",
    "\n",
    "\n",
    "def define_unique_groups(df, column=\"video_filename\"):\n",
    "    \"\"\"Define grouby object and uniques, useful idiom for dataframe loop operations.\"\"\"\n",
    "    uniques = df[column].unique()\n",
    "    grouped = df.groupby(column)\n",
    "    return uniques, grouped\n",
    "\n",
    "\n",
    "def label_dist(df, col=\"final_label\"):\n",
    "    #print(df.drop_duplicates('unique_id')[col].value_counts(dropna=False).sort_index())\n",
    "    print(df.drop_duplicates('session_id')[col].value_counts(dropna=False).sort_index())\n",
    "\n",
    "\n",
    "# # save for team to use\n",
    "# savepath = \"/data/datasets/source/ptsd/\"\n",
    "# filename = \"MP_262_joined.parquet\"\n",
    "# df2.to_parquet(os.path.join(savepath, filename))\n",
    "\n",
    "# LOAD\n",
    "df2 = pd.read_parquet(\"/data/datasets/source/ptsd/MP_262_joined.parquet\")\n",
    "\n",
    "# NOTE: you'll have to rerun the queries & processing above instead once we get new people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96295067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ptsd_bin\n",
      "0    124\n",
      "1    138\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((15472232, 47), 262, None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape, df2['session_id'].nunique(), label_dist(df2, col='ptsd_bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503935fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87dd8a29",
   "metadata": {},
   "source": [
    "# ELT pipe cleaning & EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715348c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import Tuple\n",
    "\n",
    "# def test_no_duplicates(df: pd.DataFrame, identifier: str):\n",
    "#     \"\"\"Test df for common duplications/collisions after wrangling.\n",
    "\n",
    "#     NOTE: Intended use is on a dataframe (or df subset) corresponding\n",
    "#     to 1 unique id, 1 session, 1 video. Otherwise will hang.\n",
    "\n",
    "#     df : dataframe\n",
    "\n",
    "#     identifier : str\n",
    "#         video filename, unique_id, session_id, etc\n",
    "\n",
    "#     \"\"\"\n",
    "#     assert df[\"unique_id\"].nunique() == 1\n",
    "#     assert df[\"session_id\"].nunique() == 1\n",
    "#     assert df[\"video_filename\"].nunique() == 1\n",
    "#     try:\n",
    "#         assert df[\"uploaded_at\"].nunique() == 1\n",
    "#     except AssertionError:\n",
    "#         unique_count = df[\"uploaded_at\"].nunique()\n",
    "#         print(\n",
    "#             f'{unique_count} uniques in column \"uploaded_at\" in {identifier}. Expected 1, using first index'\n",
    "#         )\n",
    "\n",
    "#     # If this fails, it means the unique_id has 2 different PTSD labels\n",
    "#     try:\n",
    "#         assert df[\"ptsd\"].nunique() == 1\n",
    "#     except:\n",
    "#         if df[\"ptsd\"].isna().sum() > 0:\n",
    "#             print(\"NaNs detected in labels\")\n",
    "#         else:\n",
    "#             raise Exception(\"dataframe has multiple ptsd labels\")\n",
    "\n",
    "\n",
    "# def norm_and_interpolate(data, num_samples) -> np.ndarray:\n",
    "#     \"\"\"Normalize and interpolate a signal.\n",
    "\n",
    "#     \"Normalize\" in this context means 0 mean, 1 standard dev.\n",
    "\n",
    "#     data : np.ndarray\n",
    "#         rows as observations, columns as features (1 col is a timeseries)\n",
    "\n",
    "#     num_samples : int\n",
    "#         desired length of output signal\n",
    "#     \"\"\"\n",
    "#     data = (data - data.mean(axis=0)) / data.std(axis=0)\n",
    "#     intrp = torch.from_numpy(data)\n",
    "#     data_interp = (\n",
    "#         F.interpolate(intrp.unsqueeze(0).unsqueeze(0), num_samples).squeeze().numpy()\n",
    "#     )\n",
    "#     return data_interp\n",
    "\n",
    "\n",
    "# def shortest_video_samples(timeseries_df: pd.DataFrame, task: str) -> int:\n",
    "#     \"\"\"Return the number of samples of the shortest video in your dataframe.\n",
    "\n",
    "#     Assumes same task (PLR, affective img, cal, etc.), otherwise,\n",
    "#     YOUR VIDS COULD BE CUT WAY TOO SHORT!\n",
    "\n",
    "#     timeseries_df : dataframe with your timeseries\n",
    "#     task : str like \"plr\" or \"calibration\"\n",
    "#     \"\"\"\n",
    "#     task_samples = {\n",
    "#         \"affective_image_set\": 2400,\n",
    "#         \"plr\": 1200,\n",
    "#         \"calibration_1\": 3300,\n",
    "#         \"calibration_2\": 3300,\n",
    "#     }\n",
    "#     num_samples = task_samples.get(task, None)\n",
    "\n",
    "#     # Find shortest video\n",
    "#     videos, grouped = define_unique_groups(timeseries_df, column=\"video_filename\")\n",
    "#     for vid in videos:\n",
    "#         temp = grouped.get_group(vid).sort_values(\"row_number\").reset_index(drop=True)\n",
    "#         # uid = temp['unique_id'].unique()[0]\n",
    "\n",
    "#         if temp.shape[0] < num_samples:\n",
    "#             num_samples = temp.shape[0]\n",
    "\n",
    "#     return num_samples\n",
    "\n",
    "\n",
    "# def wrangle_timeseries(\n",
    "#     df, features=None, task=None, deblink=insight_config.DEBLINK\n",
    "# ) -> pd.DataFrame:\n",
    "#     \"\"\"Prep timeseries data for loading into models.\n",
    "\n",
    "#     This includes trunacting time series, resampling, standardizing/normalizing, & deblinking.\n",
    "\n",
    "#     df : dataframe to process\n",
    "#     features : list of strings\n",
    "#         column names of features to include in model\n",
    "#     task : str or list of strings\n",
    "#         names of tasks to include e.g. PLR, calibration, ptsd images, etc.\n",
    "#     deblink : boolean\n",
    "#         deblink the timeseries or not\n",
    "\n",
    "#     \"\"\"\n",
    "\n",
    "#     if features is None:\n",
    "#         features = insight_config.FEATS\n",
    "\n",
    "#     # Filter df to specific task(s) and feature set\n",
    "#     if insight_config.VERBOSE:\n",
    "#         print(f\"Filtering to {task}\")\n",
    "#     timeseries_df = df[df[\"task_id_renamed\"] == task].reset_index(drop=True)\n",
    "#     timeseries_df = timeseries_df[features + insight_config.UTIL_COLS]\n",
    "\n",
    "#     # Value to truncate samples to\n",
    "#     shortest_timeseries = shortest_video_samples(timeseries_df, task)\n",
    "#     if insight_config.VERBOSE:\n",
    "#         print(f\"Truncating {task} to {shortest_timeseries} samples\")\n",
    "\n",
    "#     # Resample all to be same length, Normalize, & Repack into new DataFrame\n",
    "#     videos, grouped = define_unique_groups(timeseries_df, column=\"video_filename\")\n",
    "#     df_collector = []\n",
    "#     for vid in videos:\n",
    "#         temp = grouped.get_group(vid).sort_values(\"row_number\").reset_index(drop=True)\n",
    "\n",
    "#         # Test for common duplication issues in preprocessing\n",
    "#         # and Get values for this iteration subset\n",
    "#         test_no_duplicates(temp, vid)\n",
    "#         uid = temp[\"unique_id\"].iloc[0]\n",
    "#         sess = temp[\"session_id\"].iloc[0]\n",
    "#         upload_time = temp[\"uploaded_at\"].iloc[0]\n",
    "#         ptsd_status = temp[\"ptsd\"].iloc[0]\n",
    "\n",
    "#         # Resample & Normalize timeseries\n",
    "#         # NEED TO RESAMPLE BEFORE IF IMPLEMENTING DEBLINKING - check sampling rate for deblinker\n",
    "#         data = temp[features].values\n",
    "#         transformed_data = []\n",
    "#         for column_idx in range(data.shape[1]):\n",
    "#             column = data[:, column_idx].copy().astype(\"float\")\n",
    "#             # TODO: investigate why converstion to `float` is needed.\n",
    "#             # original Err: coming up with type `numpy.object_` that norm_interp() couldn't process\n",
    "#             tmp = norm_and_interpolate(column, shortest_timeseries)\n",
    "#             transformed_data.append(tmp)\n",
    "#         new_data = np.array(transformed_data).T\n",
    "#         # new_data = np.array(transformed_data).reshape((shortest_timeseries, len(FEATURE_SET)))\n",
    "#         # new_data = np.concatenate(transformed_data).reshape((shortest_timeseries, len(FEATURE_SET)))\n",
    "\n",
    "#         ndf = pd.DataFrame(data=new_data, columns=features)\n",
    "\n",
    "#         # New df columns\n",
    "#         ndf[\"unique_id\"] = uid\n",
    "#         ndf[\"session_id\"] = sess\n",
    "#         ndf[\"video_filename\"] = vid\n",
    "#         ndf[\"uploaded_at\"] = upload_time\n",
    "#         ndf[\"ptsd\"] = ptsd_status\n",
    "\n",
    "#         # Collect eye features from each video\n",
    "#         df_collector.append(ndf)\n",
    "\n",
    "#     prepped_df = pd.concat(df_collector, axis=0).reset_index(drop=True)\n",
    "#     if insight_config.VERBOSE:\n",
    "#         print(f\"Timeseries wrangled from {features}\")\n",
    "#         print(f\"shape: {prepped_df.shape}\")\n",
    "#         print(f\"df columns:\\n{prepped_df.columns.to_list()}\")\n",
    "#     return prepped_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73de18f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8aca840",
   "metadata": {},
   "source": [
    "##### length issue wtf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9db8b199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4872.0, 5460.0)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "60*14*5.8, 60*14*6.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "809d4210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mckinnon\n",
      "mean: 1408.958932238193\n",
      "med: 1477.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check lengths for all types of tasks\n",
    "\n",
    "rough_vid_min = { # 60fps\n",
    "    \"calibration_1\": 1650, # 27.5 s\n",
    "    \"calibration_2\": 1650,\n",
    "    \"plr\": 480, # 8 s\n",
    "    \"face_pairs\": 5460, # 5.8-6.5 sec * 14\n",
    "    \"mckinnon\": 1440 # 24 s\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "all_tasks = df2['task_id_renamed'].unique()\n",
    "\n",
    "for task in all_tasks:\n",
    "    #if task == 'calibration_1':\n",
    "    #if task == 'calibration_2':\n",
    "    #if task == 'plr':\n",
    "    #if task == 'face_pairs': #NOTE: couple very long, wtf\n",
    "    if task == 'mckinnon':\n",
    "        print(task)\n",
    "        vid_length = []\n",
    "        vids, dfg = define_unique_groups(df2[df2['task_id_renamed'] == task], column=\"video_path\")\n",
    "        for v in vids:\n",
    "            tmp = dfg.get_group(v)\n",
    "            assert tmp['task_id_renamed'].iloc[0] == task\n",
    "\n",
    "            # TODO: drop lowest fps videos\n",
    "            # print(tmp['frametimestamps'].diff().value_counts().sort_index())\n",
    "\n",
    "            #max_frame_interval = tmp['frametimestamps'].diff().value_counts().sort_index().index.max()\n",
    "            # if max_frame_interval > 20: # < 50 fps\n",
    "            #     pass # drop\n",
    "            # TODO: NEXT: why PLR fucked? check fps/0-intervals\n",
    "\n",
    "            # if tmp.shape[0] < rough_vid_min[task]:\n",
    "            #     print(tmp['session_id'].unique())\n",
    "            #     print(tmp['video_path'].unique())\n",
    "\n",
    "            vid_length.append(tmp.shape[0])\n",
    "\n",
    "        vid_length = np.array(vid_length)\n",
    "        print(f\"mean: {vid_length.mean()}\")\n",
    "        print(f\"med: {np.median(vid_length)}\")\n",
    "\n",
    "        pd.Series(vid_length).hist(bins=20)\n",
    "        plt.title(task)\n",
    "        plt.xlabel(\"rows\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18637233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad49e918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "139808a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'phone_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/yochlol/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'phone_model'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[153]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdf2\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mphone_model\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.value_counts(dropna=\u001b[38;5;28;01mFalse\u001b[39;00m).sort_index()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/yochlol/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/yochlol/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'phone_model'"
     ]
    }
   ],
   "source": [
    "df2['phone_model'].value_counts(dropna=False).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320cc181",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588e5d07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7672bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = wrangle_timeseries(\n",
    "    dataset,\n",
    "    features=FEATS,\n",
    "    task=TASK,\n",
    "    deblink=DEBLINK,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310eef2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21bc545e",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATS = [\n",
    "    'pupil_area_right',\n",
    "    'pupil_area_left',\n",
    "    'pupil_centers_right_x',\n",
    "    'pupil_centers_right_y',\n",
    "    'pupil_centers_left_x',\n",
    "    'pupil_centers_left_y',\n",
    "    'pirl',\n",
    "    'pirr',\n",
    "    'gaze_pupil_centers_left_y',\n",
    "    'gaze_pupil_centers_left_x',\n",
    "    'gaze_pupil_centers_right_y',\n",
    "    'gaze_pupil_centers_right_x',\n",
    "    'gaze_left_pitch',\n",
    "    'gaze_left_yaw',\n",
    "    'gaze_right_pitch',\n",
    "    'gaze_right_yaw',\n",
    "    'head_pitch',\n",
    "    'head_yaw',\n",
    "    'head_roll',\n",
    "    'pupil_area_right_interpolate',\n",
    "    'pupil_area_left_interpolate',\n",
    "    'pupil_centers_right_x_interpolate',\n",
    "    'pupil_centers_right_y_interpolate',\n",
    "    'pupil_centers_left_x_interpolate',\n",
    "    'pupil_centers_left_y_interpolate',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b62280a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gaze_pupil_centers_left_y\n",
      "gaze_pupil_centers_left_x\n",
      "gaze_pupil_centers_right_y\n",
      "gaze_pupil_centers_right_x\n",
      "gaze_left_pitch\n",
      "gaze_left_yaw\n",
      "gaze_right_pitch\n",
      "gaze_right_yaw\n",
      "head_pitch\n",
      "head_yaw\n",
      "head_roll\n",
      "pupil_area_right_interpolate\n",
      "pupil_area_left_interpolate\n",
      "pupil_centers_right_x_interpolate\n",
      "pupil_centers_right_y_interpolate\n",
      "pupil_centers_left_x_interpolate\n",
      "pupil_centers_left_y_interpolate\n"
     ]
    }
   ],
   "source": [
    "cols = dfcve2.columns.to_list()\n",
    "for f in FEATS:\n",
    "    if f not in cols:\n",
    "        print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe60019",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f699ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: NEXT prep timeseries for model ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6a6d0038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['session_id',\n",
       " 'task_id',\n",
       " 'video_path',\n",
       " 'block_number',\n",
       " 'event_order',\n",
       " 'event_name',\n",
       " 'event_start',\n",
       " 'event_end',\n",
       " 'block_trial',\n",
       " 'trial',\n",
       " 'category',\n",
       " 'event_category',\n",
       " 'event_type',\n",
       " 'displayed_cal_dot_at_x',\n",
       " 'displayed_cal_dot_at_y',\n",
       " 'item',\n",
       " 'list_type',\n",
       " 'row_number',\n",
       " 'frametimestamps',\n",
       " 'pupil_area_left',\n",
       " 'pupil_area_right',\n",
       " 'pupil_centers_left_x',\n",
       " 'pupil_centers_left_y',\n",
       " 'pupil_centers_right_x',\n",
       " 'pupil_centers_right_y',\n",
       " 'pirl',\n",
       " 'pirr',\n",
       " 'task_id_renamed']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfcve2.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8f59bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fdc5d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7bc2dce0",
   "metadata": {},
   "source": [
    "# normalize/standardize, truncate, resample, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1537071f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize\n",
    "\n",
    "# don't bother with unsupervised for now\n",
    "# get timeseries same length / de-ragged\n",
    "\n",
    "# # DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f3edef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DETRENDER\n",
    "from sktime.transformations.series.detrend import Detrender\n",
    "from sktime.forecasting.trend import PolynomialTrendForecaster\n",
    "\n",
    "transformer = Detrender(forecaster=PolynomialTrendForecaster(degree=3))\n",
    "data = transformer.fit_transform(pd.Series(data))\n",
    "\n",
    "# or scipy version\n",
    "from scipy.signal import detrend\n",
    "const = detrend(x, type='constant')\n",
    "linear = detrend(x, type='linear')\n",
    "\n",
    "# numpy polynomial\n",
    "DEGREE = 3\n",
    "poly_n = np.polynomial.Polynomial.fit(x, y, deg=DEGREE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f37d0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a25583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94500232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef5951b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f5e1ea0",
   "metadata": {},
   "source": [
    "# task picker (one, combo, all?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46633ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this or OneHot?\n",
    "\n",
    "def factorize_categorical_column(df, col_name=\"unique_id\") -> pd.DataFrame:\n",
    "    \"\"\"Add a new df column that converts the desired column to a numerical category.\n",
    "    `pd.factorize()` alone encodes the object as an enumerated type or categorical\n",
    "    variable.\n",
    "\n",
    "    Example: run on `unique_id` column of dataframe for leave-one-person-out\n",
    "        cross-validation, so that unique ids are ordered 0, 1, 2, ... instead\n",
    "        of string literal `unique_id`s.\n",
    "    \"\"\"\n",
    "    new_df = df.copy()\n",
    "    new_col_name = \"factorized_\" + col_name\n",
    "    new_df[new_col_name] = pd.factorize(new_df[col_name])[0]\n",
    "    return new_df\n",
    "\n",
    "# convert task to factorized feat; TODO: OneHot once McKinnon done by Research\n",
    "# df = factorize_categorical_column(df, col_name=\"task\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f65875",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cb7458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a8af17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea7085ee",
   "metadata": {},
   "source": [
    "# Modeling start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fadb31d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6dd69707",
   "metadata": {},
   "source": [
    "# * ROCKET stuff, `tsai`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5124fda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROCKET stuff (optimized/chunked for large datasets), plus ridge regressor and xgb/lgbm\n",
    "\n",
    "# catboost?\n",
    "\n",
    "# tsai (HC2, ts-chief, inception time)\n",
    "# https://www.sktime.net/en/latest/api_reference/auto_generated/sktime.classification.hybrid.HIVECOTEV2.html\n",
    "\n",
    "# hydra (angus924) repo\n",
    "# or HYDRA + SelF-Rocket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8315b6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from tsai.models.MINIROCKET_Pytorch import MiniRocketFeatures, get_minirocket_features\n",
    "from tsai.data import validation\n",
    "from tslearn.utils import to_time_series_dataset\n",
    "from tsai.all import *\n",
    "\n",
    "# def nullify_indices(properties):\n",
    "#     l = list(zip(properties['left_ips'], properties['right_ips']))\n",
    "#     nulx = []\n",
    "#     for e in l:\n",
    "#         if (int(e[1]) - int(e[0])) > 300:\n",
    "#             continue\n",
    "#         nulx += list(np.arange(int(e[0]), int(e[1])))\n",
    "#     return np.array(list(set(nulx)))\n",
    "\n",
    "\n",
    "# def nullify_blinks(tmp, nulc=['pupil_area_left', 'pupil_area_right']):\n",
    "#     tmpp = tmp.copy()\n",
    "#     foo = tmpp[['iris_area_left', 'iris_area_right']].copy()\n",
    "#     data = foo.mean(1).rolling(3).mean().fillna(method='bfill')\n",
    "#     data = (data - data.mean()).abs()\n",
    "#     x = data.values / data.values.max()\n",
    "\n",
    "#     peaks, properties = find_peaks(x, prominence=(0.4, None), height=0.3, distance=16, width=(None,300))\n",
    "#     results_half = peak_widths(x, peaks, rel_height=0.85)\n",
    "#     results_full = peak_widths(x, peaks, rel_height=1)\n",
    "#     properties[\"width_heights\"] = results_half[1]\n",
    "#     properties[\"left_ips\"] = results_half[2]\n",
    "#     properties[\"right_ips\"] = results_half[3]\n",
    "\n",
    "#     nulx = nullify_indices(properties)\n",
    "#     tmpp.loc[nulx, nulc] = np.nan\n",
    "#     return tmpp\n",
    "\n",
    "def get_tsdfs(unique_items, dfg, tscols):#categorical=False):\n",
    "    \"\"\"\n",
    "    Returns np.ndarray of time series given gropuby obj and unique items.\n",
    "\n",
    "    Args:\n",
    "    -----\n",
    "    unique_items : list of uniques, like session, video path, etc.\n",
    "    dfg : pd.DataFrame groupby object associated with unique items\n",
    "    tscols : list of df column names to include\n",
    "    categorical : [DEPRECATED] whether to process categorical or not\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    x : numpy array of time series\n",
    "\n",
    "    \"\"\"\n",
    "    df_assembler = []\n",
    "\n",
    "    for u in tqdm(unique_items):\n",
    "        tmp = dfg.get_group(u).reset_index(drop=True)\n",
    "        df_assembler.append(tmp[tscols])\n",
    "        # append time series or categorical columns\n",
    "        # categorical for rocket feats, need to factorize if so\n",
    "        #df_assembler.append(tmp[tscol] if not categorical else tmp[ycols])\n",
    "    # to_time_series_dataset() will put everything together into\n",
    "    # a square array for you by padding everything to the length\n",
    "    # of the longest single sequence\n",
    "    # but check.....might add a ton of 0 padding\n",
    "    tsd = to_time_series_dataset(df_assembler)\n",
    "    x = torch.from_numpy(tsd).permute(0,2,1).numpy()\n",
    "    return x\n",
    "\n",
    "def get_mrfs(X, splits, num_kernels=10000):\n",
    "    \"\"\"\n",
    "    Get MiniRocketFeatures in one convenient function.\n",
    "\n",
    "    Args:\n",
    "    -----\n",
    "    X : data in, torch.Tensor of shape (batchsize, channels, length)\n",
    "    splits : tuple, split idx for data, from tsai.data.validation.get_splits()\n",
    "    num_kernels : int, desired number of rocket kernels\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    X_feat : np.ndarray, minirocket features of shape (batchsize, rocket kernels, 1)\n",
    "    mrf : fitted MiniRocketFeatures model instance\n",
    "\n",
    "    \"\"\"\n",
    "    #mrf = MiniRocketFeatures(xXx.shape[1], xXx.shape[2]).to(torch.device('cuda:0'))\n",
    "    mrf = MiniRocketFeatures(X.shape[1], X.shape[2], num_features=num_kernels).to(torch.device('cuda:0'))\n",
    "    X_train = X[splits[0]]\n",
    "    mrf.fit(X_train, chunksize=128)\n",
    "    X_feat = get_minirocket_features(X, mrf, chunksize=64, to_np=True)\n",
    "    return X_feat, mrf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10046a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_for_rocket = get_tsdfs(sessions, dfg, multivar_cols2) #multivar_cols, gzc, multivar_cols2\n",
    "X = X_for_rocket[..., :390].astype(np.float32)\n",
    "\n",
    "splits3 = validation.get_splits(sessions,\n",
    "                                valid_size=0.1\n",
    "                                )\n",
    "\n",
    "mrf = MiniRocketFeatures(X.shape[1], X.shape[2]).to(default_device())\n",
    "X_train = X[splits3[0]]\n",
    "mrf.fit(X_train)\n",
    "X_feat = get_minirocket_features(X, mrf, chunksize=512, to_np=True)\n",
    "X_feat.shape, type(X_feat)\n",
    "\n",
    "rocket_df = pd.DataFrame(X_feat.squeeze(), columns=[str(i) for i in range(X_feat.shape[1])])\n",
    "rocket_df['pid'] = sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e31959c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "306a9255",
   "metadata": {},
   "source": [
    "# * other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54255a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TS-TCC (ts representation learning)\n",
    "# https://github.com/emadeldeen24/TS-TCC\n",
    "# or S3-Timeseries (shivan-grover),\n",
    "\n",
    "# MILLET\n",
    "# https://github.com/JAEarly/MILTimeSeriesClassification\n",
    "\n",
    "# TimeMIL (xiwenc1)\n",
    "\n",
    "# MPTSNet https://github.com/MUYang99/MPTSNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b957332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TabNET (new) https://github.com/dreamquark-ai/tabnet\n",
    "# PatchTST\n",
    "# TimesFM\n",
    "# ** MANTIS **"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a50b238",
   "metadata": {},
   "source": [
    "# * MANTIS\n",
    "`https://github.com/vfeofanov/mantis`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec32bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mantis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba3ec3f",
   "metadata": {},
   "source": [
    "# * LGBM or other logo loops, sklearn models, DummyClassifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a37bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# light gbm or other for LOGO? loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61765ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e522256",
   "metadata": {},
   "source": [
    "#### original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd40971",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import (train_test_split, LeaveOneGroupOut,\n",
    "                                     StratifiedKFold, GroupKFold, KFold)\n",
    "from sklearn.metrics import (roc_curve, auc, RocCurveDisplay,\n",
    "                             precision_recall_curve, PrecisionRecallDisplay,\n",
    "                             classification_report, confusion_matrix, ConfusionMatrixDisplay,\n",
    "                             matthews_corrcoef)\n",
    "\n",
    "\n",
    "# sk_models = dict(\n",
    "#     {\n",
    "#         \"dummy\": DummyClassifier(strategy=\"most_frequent\"),\n",
    "#         \"rf\": RandomForestClassifier(),\n",
    "#         \"ridge\": RidgeClassifier(),\n",
    "#         \"logreg\": LogisticRegression(random_state=99),\n",
    "#         \"svc\": SVC(gamma=\"auto\") ## differently tuned SVCs\n",
    "#     }\n",
    "# )\n",
    "\n",
    "\n",
    "# Set CV type\n",
    "stratified = 'logo'#'stratified'#'logo'\n",
    "num_folds = 5\n",
    "\n",
    "\n",
    "if stratified == 'stratified':\n",
    "    folds = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=90)\n",
    "elif stratified == 'logo':\n",
    "    folds = LeaveOneGroupOut()\n",
    "elif stratified == 'group':\n",
    "    folds = GroupKFold(n_splits=num_folds)\n",
    "else:\n",
    "    folds = KFold(n_splits=num_folds, shuffle=True, random_state=2045)\n",
    "\n",
    "\n",
    "\n",
    "# Collect feature importances for each fold\n",
    "#feature_importance = pd.DataFrame({'feature': feats})\n",
    "\n",
    "\n",
    "oof_preds = np.full((X.shape[0], 13), np.nan)\n",
    "#oof_scores = np.full((X.shape[0], 2), np.nan)\n",
    "\n",
    "# Gather split indexes for each fold & Train\n",
    "for n_fold, (train_idx, valid_idx) in enumerate(folds.split(X[feats],\n",
    "                                                            X[target],\n",
    "                                                            X['fid']\n",
    "                                                           )\n",
    "                                               ):\n",
    "    print('n_fold: ', n_fold, '  valid_uids: ', X['unique_id'].values[valid_idx])\n",
    "    train_labels = X[target].values[train_idx]\n",
    "    valid_labels = X[target].values[valid_idx]\n",
    "    print(f'train: {train_labels}')\n",
    "    print(f'valid: {valid_labels}')\n",
    "    # check for overlap people in training & validation\n",
    "    training_uids = list(X['unique_id'].values[train_idx])\n",
    "    validation_uids = list(X['unique_id'].values[valid_idx])\n",
    "    overlap = list(set(validation_uids) & set(training_uids))\n",
    "    print(f'train/valid overlap: {len(overlap)}')\n",
    "    if len(overlap)>0:\n",
    "        print('WARNING: TRAINING & VALIDATION UID OVERLAP')\n",
    "\n",
    "    # Split the data\n",
    "    X_train, y_train = X[feats].iloc[train_idx], X[target].iloc[train_idx]\n",
    "    X_valid, y_valid = X[feats].iloc[valid_idx], X[target].iloc[valid_idx]\n",
    "\n",
    "    # Train the models (Majotiry class baseline & LogReg)\n",
    "    dummy_clf = DummyClassifier(strategy='most_frequent')\n",
    "    dummy_clf.fit(X_train, y_train)\n",
    "\n",
    "    svc1 = SVC(kernel=\"rbf\", gamma=\"auto\", probability=True) # toggle proba=True, beware of proba=True leaky CV\n",
    "    svc2 = SVC(kernel=\"rbf\", gamma=\"scale\", probability=True)\n",
    "    svc3 = SVC(kernel=\"poly\", gamma=\"auto\", probability=True)\n",
    "    svc4 = SVC(kernel=\"poly\", gamma=\"scale\", probability=True)\n",
    "\n",
    "    ridge = RidgeClassifier(random_state=6)\n",
    "    rf = RandomForestClassifier(random_state=6)\n",
    "    dt = DecisionTreeClassifier(random_state=6)\n",
    "    logreg = LogisticRegression(random_state=6)\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "    for m in [svc1, svc2, svc3, svc4, ridge, rf, dt, logreg, knn]:\n",
    "        m.fit(X_train, y_train)\n",
    "\n",
    "    model = [dummy_clf, svc1, svc2, svc3, svc4, ridge, rf, dt, logreg, knn]\n",
    "\n",
    "\n",
    "    # Collect Validation Predictions\n",
    "    oof_preds[valid_idx, 0] = n_fold\n",
    "    oof_preds[valid_idx, 1] = X['fid'].iloc[valid_idx]\n",
    "    oof_preds[valid_idx, 2] = dummy_clf.predict(X_valid)\n",
    "    # oof_preds[valid_idx, 3] = svc1.predict(X_valid)\n",
    "    # oof_preds[valid_idx, 4] = svc2.predict(X_valid)\n",
    "    # oof_preds[valid_idx, 5] = svc3.predict(X_valid)\n",
    "    # oof_preds[valid_idx, 6] = svc4.predict(X_valid)\n",
    "    oof_preds[valid_idx, 3] = svc1.predict_proba(X_valid)[:, 1]\n",
    "    oof_preds[valid_idx, 4] = svc2.predict_proba(X_valid)[:, 1]\n",
    "    oof_preds[valid_idx, 5] = svc3.predict_proba(X_valid)[:, 1]\n",
    "    oof_preds[valid_idx, 6] = svc4.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "    oof_preds[valid_idx, 7] = ridge.predict(X_valid) #<\n",
    "    oof_preds[valid_idx, 8] = rf.predict_proba(X_valid)[:, 1]\n",
    "    oof_preds[valid_idx, 9] = dt.predict_proba(X_valid)[:, 1]\n",
    "    oof_preds[valid_idx, 10] = logreg.predict_proba(X_valid)[:, 1]\n",
    "    oof_preds[valid_idx, 11] = knn.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "    oof_preds[valid_idx, 12] = y_valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bdc7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = oof_preds[:, 2:-1].copy()\n",
    "y_pred = (y_proba >= .5).astype('int')\n",
    "y_true = oof_preds[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfdf20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#oof_preds[:3, 2:-1]\n",
    "oof_preds[:, 11] # 2 is Dummy: 7? 9?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431287bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curves w probas\n",
    "titles = [\n",
    "    \"SVC(kernel='rbf', gamma='auto')\",\n",
    "    \"SVC(kernel='rbf', gamma='scale')\",\n",
    "    \"SVC(kernel='poly', gamma='auto')\",\n",
    "    \"SVC(kernel='poly', gamma='scale')\",\n",
    "    \"RidgeClassifier()\",\n",
    "    \"RandomForestClassifier()\",\n",
    "    \"DecisionTreeClassifier()\",\n",
    "    \"LogisticRegression()\",\n",
    "    \"KNeighborsClassifier()\"\n",
    "]\n",
    "models = [svc1, svc2, svc3, svc4, ridge, rf, dt, logreg, knn]\n",
    "for i, m in enumerate(models):\n",
    "    print(\"============================================\")\n",
    "    print(m)\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_proba[:, i+1]) # i+1 here bc no dummy, dummy is 0\n",
    "    auc_ = roc_auc_score(y_true, y_proba[:, i+1])\n",
    "\n",
    "    plt.plot(fpr, tpr)\n",
    "    mplcyberpunk.add_underglow()\n",
    "    plt.plot([0, 1], [0, 1], \"--\", lw=1)\n",
    "    plt.xlabel(\"False Positive Rate (Positive label: 1)\")\n",
    "    plt.ylabel(\"True Positive Rate (Positive label: 1)\")\n",
    "    plt.title(f\"ROC AUC: {round(auc_, 2)}\")\n",
    "    plt.show()\n",
    "\n",
    "    # disp = RocCurveDisplay.from_predictions(y_true, y_proba[:, i])\n",
    "    # disp.ax_.set_title(titles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4309e07a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5279d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c6add9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8723c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42646c89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfb6226",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b378120",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43a549d2",
   "metadata": {},
   "source": [
    "# Ordinal TSC\n",
    "https://github.com/RafaAyGar/aeon/blob/main/examples/classification/tsoc_methods.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242d1f33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4830062",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4337580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7652c09c",
   "metadata": {},
   "source": [
    "# HC2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db041872",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from aeon.classification.hybrid import HIVECOTEV1, HIVECOTEV2\n",
    "\n",
    "hc1 = HIVECOTEV1()\n",
    "hc2 = HIVECOTEV2(time_limit_in_minutes=0.2)\n",
    "hc2.fit(X_train, y_train)\n",
    "y_pred = hc2.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0298686c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hc2.fit(X_train_mv, y_train_mv)\n",
    "y_pred = hc2.predict(X_test_mv)\n",
    "\n",
    "accuracy_score(y_test_mv, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee87a84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60144375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091c41e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98f24d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8caf994b",
   "metadata": {},
   "source": [
    "# * FLAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b450fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "automl = AutoML()\n",
    "automl.fit(X_train, y_train, task=\"classification\")\n",
    "automl.fit(X_train, y_train, task=\"classification\", early_stop=True)\n",
    "automl.fit(X_train, y_train, task=\"seq-classification\") # seq-?\n",
    "#automl.fit(X_train, y_train, task=\"classification\", time_budget=-1)\n",
    "#automl.fit(X_train, y_train, task=\"classification\", time_budget=-300, n_split=5)\n",
    "#automl.fit(X_train, y_train, task=\"classification\", time_budget=60) =300 (seconds)\n",
    "#automl.fit(X_train, y_train, task=\"classification\", time_budget=300, metric=\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43a8890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853324f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a97e188e",
   "metadata": {},
   "source": [
    "# $ Eval (separate script?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c75d39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    matthews_corrcoef,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    ConfusionMatrixDisplay,\n",
    "    RocCurveDisplay,\n",
    "    roc_auc_score,\n",
    "    PrecisionRecallDisplay\n",
    ")\n",
    "import mplcyberpunk\n",
    "plt.style.use(\"cyberpunk\")\n",
    "\n",
    "path = \"foo.parquet\"\n",
    "df = pd.read_parquet(path)\n",
    "\n",
    "\n",
    "df['preds'] = (df['output'] > 0.5).astype(int)\n",
    "df['targets'] = df['targets'].astype(int)\n",
    "\n",
    "df['targets'].value_counts()\n",
    "neg = 602\n",
    "pos = 134\n",
    "\n",
    "baseline = pos / (neg+pos)\n",
    "print(baseline)\n",
    "\n",
    "\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(df['targets'], df['preds'], cmap='Purples')\n",
    "mcc_ = matthews_corrcoef(df['targets'], df['preds'])\n",
    "f1_ = f1_score(df['targets'], df['preds'])\n",
    "plt.title(f\"test set: MCC = {round(mcc_, 3)}, F1 = {round(f1_, 3)}\")\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(df['targets'], df['preds']))\n",
    "\n",
    "auc = roc_auc_score(df['targets'], df['preds'])\n",
    "\n",
    "RocCurveDisplay.from_predictions(df['targets'], df['output'])\n",
    "plt.show()\n",
    "\n",
    "PrecisionRecallDisplay.from_predictions(df['targets'], df['output'])\n",
    "plt.hlines(baseline, xmin=0, xmax=1, colors='grey', linestyles=\"--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdfb4ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47a0a335",
   "metadata": {},
   "source": [
    "# Feature importance, SHAP, LOFO, etc... (by task, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd9f720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895a4439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c481da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f98163fd",
   "metadata": {},
   "source": [
    "# * SEPARATE ENVIRONMENT `aeon toolkit` DTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aef889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aeon toolkit SEPARATE ENVIRONMENT\n",
    "\n",
    "# alternative == https://github.com/pollen-robotics/dtw\n",
    "\n",
    "# https://www.aeon-toolkit.org/en/latest/getting_started.html#classification\n",
    "import numpy as np\n",
    "from aeon.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "\n",
    "X = [[[1, 2, 3, 4, 5, 6, 7]],  # 3D array example (univariate)\n",
    "     [[4, 4, 4, 5, 6, 7, 3]]]  # Two samples, one channel, seven series length\n",
    "\n",
    "y = [0, 1]  # class labels for each sample (int or str)\n",
    "\n",
    "X = np.array(X)\n",
    "\n",
    "y = np.array(y)\n",
    "\n",
    "clf = KNeighborsTimeSeriesClassifier(distance=\"dtw\")\n",
    "\n",
    "clf.fit(X, y)  # fit the classifier on train data\n",
    "\n",
    "\n",
    "X_test = np.array([[2, 2, 2, 2, 2, 2, 2], [4, 4, 4, 4, 4, 4, 4]])\n",
    "\n",
    "clf.predict(X_test)  # make class predictions on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b059b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06817939",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c94d57c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d7b7f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089ba3cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45231f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5299c0d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961d9041",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0786867a",
   "metadata": {},
   "source": [
    "# Save model (sklearn style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d677d5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train w all the data\n",
    "svc2 = SVC(kernel=\"rbf\", gamma=\"scale\")\n",
    "svc2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44130b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"scaler\", scaler),\n",
    "    (\"pca\", pca),\n",
    "    (\"svc2\", svc2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555080bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab263dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "#joblib.dump(pipeline, \"saved_model.joblib\")\n",
    "joblib.dump(pipeline, \"saved_model.joblib\", protocol=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de88381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load & predict new\n",
    "import joblib\n",
    "\n",
    "#model_file = \"scaler_pca2D_SVC2.joblib\"\n",
    "model_file = \"scaler_pca3D_SVC2.joblib\"\n",
    "model_dir = \"/data/models/ptsd_classification/scaler_pca3D_SVC2/\"\n",
    "\n",
    "loaded_pipeline = joblib.load(model_dir + model_file)\n",
    "new_data = df.iloc[:5, 2:12].values\n",
    "predictions = loaded_pipeline.predict(new_data)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8b76f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14f4698",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf3c9f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0a747b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4555cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yochlol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
